# üóûÔ∏è Weekly AI Transcription Digest

**GTM Engineer Intern: 48-Hour Automated Newsletter Challenge**

Welcome to the **Weekly AI Transcription Digest**, a fully automated newsletter system focused on *Speech-to-Text and AI Transcription* news and research. This project was built as part of a 48-hour challenge to demonstrate a production-grade, scalable, and automated newsletter platform.

---

## üìå Project Overview

- **Topic**: Speech-to-Text & AI Transcription  
- **Automated**: End-to-end content generation, curation, and email delivery  
- **Sources**: RSS feeds, web scraping, arXiv, Google News, Product Hunt  
- **LLM Summarization**: GPT-based summarization of stories  
- **Distribution**: Mailchimp  
- **Automation**: n8n for scheduling and monitoring  
- **Database**: Neon (PostgreSQL-compatible)  

---

## üöÄ Features

‚úÖ Automated multi-source content collection  
‚úÖ Summarization and curation using LLMs  
‚úÖ Markdown to HTML conversion for professional formatting  
‚úÖ Mailchimp integration to send campaigns to subscribers  
‚úÖ n8n workflow to trigger newsletters on a schedule  
‚úÖ Error-handling notifications via email  
‚úÖ Subscriber signup page hosted on Mailchimp  
‚úÖ Clean, documented, and modular codebase  
‚úÖ Designed for 1000+ subscribers scalability  

---

## üóÇÔ∏è Tech Stack

- **Backend**: Python (Flask)  
- **Automation**: n8n  
- **Web Scraping**: Playwright, RSS  
- **LLM**: OpenAI GPT  
- **Database**: Neon (PostgreSQL)  
- **Email**: Mailchimp  
- **Deployment**: Local (with ngrok for webhook testing)  
- **Version Control**: GitHub  

---

## üèóÔ∏è Architecture

```mermaid
flowchart TD
  A[RSS & Web Scraping] --> B[Python LLM Summarization]
  B --> C[Markdown Generation]
  C --> D[HTML Conversion]
  D --> E[Mailchimp Campaign API]
  B --> F[Neon DB Save]
  E --> G[Subscribers]
  H[n8n] --> A
  H --> E
  H --> I[Error Notifications]
```
---
## ‚öôÔ∏è Setup & Running Locally

### 1Ô∏è‚É£ Clone the repository

```bash
git clone https://github.com/your-username/weekly-ai-transcription-digest.git
cd weekly-ai-transcription-digest
```
### 2Ô∏è‚É£ Install dependencies
```bash
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```
### 3Ô∏è‚É£ Set environment variables

Create a `.env` file in the root directory with the following:

```bash
OPENAI_API_KEY=your_openai_api_key
MAILCHIMP_API_KEY=your_mailchimp_api_key
MAILCHIMP_SERVER_PREFIX=usX
MAILCHIMP_LIST_ID=your_list_id
NEON_DB_URL=your_neon_database_connection_url
```
### 4Ô∏è‚É£ Run the flask server
```bash
python server.py
```
### 5Ô∏è‚É£ Expose Localhost with ngrok

Since n8n on the cloud cannot access your localhost directly, you need to tunnel:

```bash
ngrok http 5000
```
Copy the https:// URL generated by ngrok.

Use this ngrok URL in your n8n HTTP Request node to call the /generate-newsletter endpoint.

## 6Ô∏è‚É£ Configure n8n Workflow
‚úÖ Add a Cron node to trigger the workflow (e.g., every Monday 9AM)
‚úÖ Add an HTTP Request node pointing to your ngrok URL (POST request)
‚úÖ Add an Error Trigger node connected to an Email node for error reporting
‚úÖ Connect the nodes in this sequence:
```bash
Cron ‚û°Ô∏è HTTP Request ‚û°Ô∏è Error Trigger ‚û°Ô∏è Email
```
‚úÖ Save and activate your n8n workflow.
-At this point, you should have a fully automated pipeline:

-Scheduled newsletter generation

-Summarization + content curation

-Database save + Mailchimp delivery

-Monitoring + error alerts


